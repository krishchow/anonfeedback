---
layout: post
title: "RE: Anonymous feedback responses"
date: Fri, 21 Oct 2016 15:17:36 EDT
nav: post
category: CSC108
tags: [4045]
---

* content
{:toc}

[quote]I think it is highly unfair that certain CSC108 classes are allowed to write their codes on the computer, while others have to us paper. unless their is some measure taken to insure that students cannot check whether their code is correct or not on the computer, all students should be allowed to use computers, or all students should write on paper.[/quote]
<!-- more -->
<p>\n\n[url=https://mcs.utm.utoronto.ca/~mybb/utmcs/showthread.php?tid=4268&pid=12362#pid12362]You don't have to worry about computer-based tests this term[/url]. That being said, I'm disappointed that we won't be able to run one section on computers. I agree that it's more natural for programming tests to be on a machine, where you have been doing the majority of your work. However, it's logistically challenging to get our tests (and final exam) on the computer, and it's not [i]proven[/i] that there is benefit in doing so. \n\nWe were hoping, by running one section in a computer-based test and others on paper, that we would be able to collect evidence about the impact of a computer-based test on students and, simultaneously, that we would be developing the infrastructure necessary on this campus to run such tests. If we were able to demonstrate that students do far better  in a computer based environment, then we would have a stronger case for getting other units on campus to work with us to offer such tests. \n\nSo, to your question: would it have been unfair to have some students writing on paper and some on the computer? I don't know yet. I [i]think[/i] so. If I were to make a prediction, I would guess that about a quarter of students will do far worse on a computer-based test than on paper (since they are less likely to get partial credit), that about half will do better (by about one letter grade), and that one quarter will do neither better nor worse. To guard against that, our experimental setup included a normalization step: all students (computer-based or not) would have completed the first two questions (the short-answer questions) on paper. Then, we would have used results on those two questions to scale the results of the second question [i]up[/i] for whichever group (computer-based or paper-based) did worse. In essence: the mean on the second two questions would have been the same whether you wrote the test on paper or on the computer. It's not perfect, but I believe that is more likely to benefit students than it is to be detrimental to anyone.\n\nWhere does that leave us? I hope we'll be able to run this in future terms. The issue that terminated the experiment this term was the availability of the lab: computing services was unable to get the machines in CCT set up for today's test without significantly decreasing the availability of the lab for other courses that might need it today. After a meeting earlier this week, I think we now have a viable plan for getting the labs set up for our tests without disrupting other courses, so I'm hoping we'll be able to run this study in the winter term, with CSC148.</p>
